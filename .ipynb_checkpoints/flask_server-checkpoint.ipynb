{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289097e-9ae8-49b2-810c-1a4cfeac4f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:6006\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748681995036-1748218298711-1747985122592-KIA.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748681995041-1748313651762-1748248087723-bam.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748995851305-1747985122592-KIA.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748995851320-1747985357221-test2.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748995851330-1748227248817-BALL.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748999477645-KakaoTalk_20250601_082515601.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748999477665-KakaoTalk_20250601_082515601_01.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748999477680-KakaoTalk_20250601_082515601_02.jpg\n",
      "✅ 분류 완료: 1749395903400-2.jpg → people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 00:18:38] \"POST /classify HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 분류 완료: 1749395903427-3.jpg → landscape\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748681995036-1748218298711-1747985122592-KIA.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748681995041-1748313651762-1748248087723-bam.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748995851305-1747985122592-KIA.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748995851320-1747985357221-test2.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748995851330-1748227248817-BALL.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748999477645-KakaoTalk_20250601_082515601.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748999477665-KakaoTalk_20250601_082515601_01.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1748999477680-KakaoTalk_20250601_082515601_02.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1749428791415-KakaoTalk_20250603_123523901_03.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1749428792921-KakaoTalk_20250603_123523901_04.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1749428793589-KakaoTalk_20250603_123523901_05.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1749428924983-KakaoTalk_20250526_123755697.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1749428925467-KakaoTalk_20250526_123755697_01.jpg\n",
      "❌ 파일 없음: C:/Users/smhrd/Desktop/pokachip/server/uploads\\1749428925511-KakaoTalk_20250526_123755697_02.jpg\n",
      "✅ 분류 완료: 1749428997722-1748503604064-KakaoTalk_20250529_162616991.jpg → food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 09:30:13] \"POST /classify HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 분류 완료: 1749428997757-1748503604085-KakaoTalk_20250529_162616991_01.jpg → landscape\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify\n",
    "import pymysql\n",
    "import torch\n",
    "import os\n",
    "import requests  # ✅ 추가\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ✅ 디바이스 설정 (GPU가 있으면 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ✅ Fine-tuned CLIP 모델 로드\n",
    "model = CLIPModel.from_pretrained(\"./clip_finetuned_model\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"./clip_finetuned_model\")\n",
    "model.eval()\n",
    "\n",
    "# ✅ 분류 대상 태그 클래스 (수정 가능)\n",
    "class_names = [\"food\", \"people\", \"landscape\", \"accommodation\"]\n",
    "\n",
    "# ✅ 이미지 분류 함수 (image_path → image_url로 변경)\n",
    "def predict_tag(image_url):\n",
    "    image = Image.open(requests.get(image_url, stream=True).raw).convert(\"RGB\")\n",
    "    inputs = processor(text=class_names, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = outputs.logits_per_image.softmax(dim=1)\n",
    "        pred_index = torch.argmax(probs).item()\n",
    "        return class_names[pred_index]\n",
    "\n",
    "# ✅ MySQL DB 접속 설정 (포트 3307)\n",
    "DB_CONFIG = {\n",
    "    'host': 'project-db-cgi.smhrd.com',\n",
    "    'port': 3307,\n",
    "    'user': 'cgi_24K_AI4_p3_2',\n",
    "    'password': 'smhrd2',  # ← 본인 비밀번호로 변경\n",
    "    'db': 'cgi_24K_AI4_p3_2',         # ← 본인 DB 이름으로 변경\n",
    "    'charset': 'utf8mb4'\n",
    "}\n",
    "\n",
    "# ✅ VSCode 서버 쪽 uploads 폴더 절대 경로 (이제 사용 안함)\n",
    "UPLOADS_DIR = \"C:/Users/smhrd/Desktop/pokachip/server/uploads\"\n",
    "\n",
    "# ✅ Flask API 엔드포인트: /classify\n",
    "@app.route('/classify', methods=['POST'])\n",
    "def classify_images():\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    # tags가 비어있는 항목들만 선택\n",
    "    cursor.execute(\"SELECT photo_idx, file_name FROM photo_info WHERE tags IS NULL OR tags = ''\")\n",
    "    photos = cursor.fetchall()\n",
    "\n",
    "    classified_count = 0\n",
    "\n",
    "    for photo in photos:\n",
    "        photo_idx = photo['photo_idx']\n",
    "        # 슬래시 정규화 + 파일명만 추출\n",
    "        filename = os.path.basename(photo['file_name'].replace('\\\\', '/'))\n",
    "\n",
    "        # ✅ 이미지 URL 경로로 변경 (Node.js 서버 주소로 바꿔야 함)\n",
    "        image_url = f\"https://your-node-app.onrender.com/uploads/{filename}\"\n",
    "\n",
    "        try:\n",
    "            tag = predict_tag(image_url)\n",
    "            cursor.execute(\"UPDATE photo_info SET tags = %s WHERE photo_idx = %s\", (tag, photo_idx))\n",
    "            conn.commit()\n",
    "            print(f\"✅ 분류 완료: {filename} → {tag}\")\n",
    "            classified_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 예측 실패 ({filename}): {e}\")\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return jsonify({\n",
    "        \"status\": \"success\",\n",
    "        \"classified\": classified_count\n",
    "    })\n",
    "\n",
    "# ✅ 서버 실행\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=6006)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e26faa-3ded-45e6-beb1-c76fd234e49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.32.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  10.2/10.5 MB 53.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 36.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.32.2-py3-none-any.whl (509 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 46.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.32.2 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.52.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68be7fdb-12cd-4893-bcfa-99b4302ee531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4e464-edbf-4026-99a5-5031a4f296a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698acab-fc6f-469c-b4fa-debc306a300a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2404d5-1013-4cdf-a798-1dbc8d4fa61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd00c1-ce9e-4259-aac4-6f3b280440a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffeb909-2394-428e-a01c-c0015c4892ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78edf77-c20f-46ea-977e-06d36918bb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c3135-50a1-4008-bdf1-82370920798e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf3d00-2dd7-46d0-9c7c-582486de9958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a822bff-7f9c-43d0-b7de-1fc6f2b3fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd96ce-0817-4d5e-b905-663f225603e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6cb01-f307-4e86-90b8-a281148bb883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479c0e6-b732-4561-b2ab-a1294920710d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c5fa73-cd72-48ad-906f-7271f6e1c288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff494a-6190-4151-bc07-1afb216a13d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389581f-1d85-46fb-9b78-d6ed41e833a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be8ee4-4ce2-4f9f-ba47-3a6377536a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f408a0-1dc8-4c33-b6eb-54fd3ee49ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715704a-9f65-4122-82bb-718347071dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
